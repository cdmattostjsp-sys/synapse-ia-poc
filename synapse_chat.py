import re
import os
import json
import streamlit as st
from datetime import datetime
from typing import List, Dict

# === OpenAI (SDK novo) ===
try:
    from openai import OpenAI
    _client_ok = True
except Exception:
    _client_ok = False

# -------------------------------------------------
# CONFIGURA√á√ÉO DA P√ÅGINA
# -------------------------------------------------
st.set_page_config(
    page_title="Synapse.IA ‚Äì POC TJSP",
    page_icon="üß†",
    layout="wide"
)

st.markdown("# üß† Synapse.IA ‚Äî POC TJSP")
st.caption("Chat √∫nico com **Agente Orquestrador** e **Agentes Especializados** (PCA, DFD, ETP, TR, Contrato, Fiscaliza√ß√£o, Checklist).")

# -------------------------------------------------
# SEGREDO (CHAVE)
# -------------------------------------------------
if "openai_api_key" not in st.secrets:
    st.warning("""Adicione a chave da OpenAI em **Settings ‚Üí Secrets** do Streamlit Cloud:""")
    client = None
else:
    client = OpenAI(api_key=st.secrets["openai_api_key"])

if not _client_ok:
    st.error("Pacote `openai` n√£o encontrado. Garanta que seu `requirements.txt` cont√©m `openai`.")
    st.stop()

# -------------------------------------------------
# NORMAS BASE
# -------------------------------------------------
NORMAS_BASE = [
    "Lei 14.133/2021 (Nova Lei de Licita√ß√µes e Contratos)",
    "Decreto Estadual 67.381/2022",
    "Provimento CSM 2724/2023",
    "Manuais TJSP de Licita√ß√µes e Contratos (2025)",
    "Boas pr√°ticas TCU/TCE-SP"
]

# -------------------------------------------------
# PROMPTS EXTERNALIZADOS
# -------------------------------------------------
def load_prompt(agent: str) -> str:
    """Carrega prompt externo (JSON) com base no nome do agente"""
    base_path = "./prompts"
    path = os.path.join(base_path, f"{agent}.json")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("prompt", "")
    return f"Voc√™ √© o Agente {agent}."

# Ordem oficial dos agentes
AGENT_ORDER = ["PCA", "DFD", "ETP", "TR", "CONTRATO", "FISCALIZACAO", "CHECKLIST"]

# -------------------------------------------------
# FUN√á√ïES AUXILIARES
# -------------------------------------------------
def progresso(stage: str) -> str:
    marcadores = []
    for s in AGENT_ORDER:
        if st.session_state.artefatos.get(s):
            marcadores.append(f"[X] {s}")
        else:
            marcadores.append(f"[ ] {s}")
    return "üìä Progresso atual: " + " ".join(marcadores)

def proximo_artefato(stage: str) -> str:
    try:
        idx = AGENT_ORDER.index(stage)
        return AGENT_ORDER[idx + 1] if idx + 1 < len(AGENT_ORDER) else None
    except ValueError:
        return None

def call_agent(stage: str, user_text: str, history: List[Dict]) -> Dict:
    """Chama agente especializado. Retorna estrutura com insumos classificados (‚úÖ/‚ö†Ô∏è/‚ùå)."""
    system_prompt = load_prompt(stage) + "\n\nInstru√ß√µes gerais:\n"
    system_prompt += (
        "1) Seja claro e institucional.\n"
        "2) Pergunte insumos obrigat√≥rios se faltarem.\n"
        "3) Estruture sa√≠da em se√ß√µes.\n"
        "4) Classifique cada insumo em ‚úÖ Pronto, ‚ö†Ô∏è Parcial ou ‚ùå Pendente.\n"
        "5) Fundamente nas normas aplic√°veis.\n"
        f"Normas de refer√™ncia: {', '.join(NORMAS_BASE)}.\n"
        "6) Ao final, sugira o pr√≥ximo passo.\n"
        "IMPORTANTE: responda SEMPRE em JSON v√°lido."
    )

    ctx = [f"{m['role']}: {m['content']}" for m in history[-4:]]
    context_block = "\n".join(ctx) if ctx else "Sem hist√≥rico relevante."

    user_prompt = (
        f"Etapa: {stage}\n"
        f"Contexto recente:\n{context_block}\n\n"
        f"Entrada do usu√°rio:\n{user_text}\n\n"
        "Responda em formato JSON estruturado:\n"
        "{ 'insumos': { 'objeto': '‚úÖ', 'justificativa': '‚ö†Ô∏è' }, 'resumo': 'texto estruturado' }"
    )

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=1000
        )
        conteudo = resp.choices[0].message.content.strip()
        try:
            return json.loads(conteudo)
        except:
            # fallback: mostra texto cru se n√£o for JSON
            return {"resumo": conteudo, "insumos": {}}
    except Exception as e:
        return {"resumo": f"‚ö†Ô∏è Erro ao consultar modelo: {e}", "insumos": {}}

def render_resumo(resumo):
    """Renderiza o campo 'resumo' do JSON como texto amig√°vel"""
    if not resumo:
        return
    
    st.markdown("### üìÑ Resumo")
    
    if isinstance(resumo, dict):
        for chave, valor in resumo.items():
            if isinstance(valor, dict):
                st.markdown(f"**{chave.capitalize()}:**")
                for subk, subv in valor.items():
                    st.markdown(f"- {subk.capitalize()}: {subv}")
            else:
                st.markdown(f"- **{chave.capitalize()}**: {valor}")
    else:
        st.markdown(resumo)

def render_insumos(insumos: Dict):
    """Renderiza insumos como tabela colorida"""
    if not insumos:
        return
    st.markdown("### üìå Status dos Insumos")
    for chave, valor in insumos.items():
        if valor == "‚úÖ":
            cor = "green"
        elif valor == "‚ö†Ô∏è":
            cor = "orange"
        elif valor == "‚ùå":
            cor = "red"
        else:
            cor = "gray"
        st.markdown(f"- **{chave.capitalize()}**: <span style='color:{cor}; font-weight:bold'>{valor}</span>", unsafe_allow_html=True)

# -------------------------------------------------
# ESTADO DO CHAT
# -------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_stage" not in st.session_state:
    st.session_state.current_stage = "PCA"
if "artefatos" not in st.session_state:
    st.session_state.artefatos = {}
if "log_normativo" not in st.session_state:
    st.session_state.log_normativo = []

# Mensagem inicial
if not st.session_state.messages:
    st.session_state.messages.append({
        "role": "assistant",
        "content": (
            "Ol√°! Sou o **Agente Orquestrador** do Synapse.IA. "
            "Antes de iniciar, precisamos verificar se a contrata√ß√£o est√° no **Plano de Contrata√ß√µes Anual (PCA)**. "
            "Deseja come√ßar pelo PCA?"
        )
    })

# Render hist√≥rico
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Entrada do usu√°rio
user_input = st.chat_input("Descreva seu pedido ou responda √†s perguntas do agente...")

if user_input:
    # salvar entrada
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # chamar agente
    stage = st.session_state.current_stage
    resposta = call_agent(stage, user_input, st.session_state.messages)

    # salvar e mostrar resultado
    if "resumo" in resposta:
        st.session_state.artefatos[stage] = resposta
        st.session_state.messages.append({"role": "assistant", "content": str(resposta["resumo"])})
        with st.chat_message("assistant"):
            render_resumo(resposta.get("resumo"))
            render_insumos(resposta.get("insumos", {}))

        # log normativo
        st.session_state.log_normativo.append({
            "etapa": stage,
            "entrada": user_input,
            "saida": resposta
        })

        # sugerir pr√≥xima etapa
        prox = proximo_artefato(stage)
        if prox:
            st.session_state.current_stage = prox
            sugestao = f"{progresso(stage)}\n\nüëâ Pr√≥ximo passo sugerido: **{prox}**. Deseja avan√ßar?"
            st.session_state.messages.append({"role": "assistant", "content": sugestao})
            with st.chat_message("assistant"):
                st.markdown(sugestao)
