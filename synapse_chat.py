import re
import os
import json
import streamlit as st
from datetime import datetime
from typing import List, Dict

# === OpenAI (SDK novo) ===
try:
    from openai import OpenAI
    _client_ok = True
except Exception:
    _client_ok = False

# -------------------------------------------------
# CONFIGURA√á√ÉO DA P√ÅGINA
# -------------------------------------------------
st.set_page_config(
    page_title="Synapse.IA ‚Äì POC TJSP",
    page_icon="üß†",
    layout="wide"
)

st.markdown("# üß† Synapse.IA ‚Äî POC TJSP")
st.caption("Chat √∫nico com **Agente Orquestrador** e **Agentes Especializados** (PCA, DFD, ETP, Pesquisa de Pre√ßos, ITF, Mapa de Riscos, TR, Parecer Jur√≠dico, Edital, Contrato, Fiscaliza√ß√£o, Checklist).")

# -------------------------------------------------
# SEGREDO (CHAVE)
# -------------------------------------------------
if "openai_api_key" not in st.secrets:
    st.warning("‚ö†Ô∏è Adicione a chave da OpenAI em **Settings ‚Üí Secrets** do Streamlit Cloud")
    client = None
else:
    client = OpenAI(api_key=st.secrets["openai_api_key"])

if not _client_ok:
    st.error("Pacote `openai` n√£o encontrado. Garanta que seu `requirements.txt` cont√©m `openai`.")
    st.stop()

# -------------------------------------------------
# NORMAS BASE
# -------------------------------------------------
NORMAS_BASE = [
    "Lei 14.133/2021 (Nova Lei de Licita√ß√µes e Contratos)",
    "Decreto Estadual 67.381/2022",
    "Provimento CSM 2724/2023",
    "Manuais TJSP de Licita√ß√µes e Contratos (2025)",
    "Boas pr√°ticas TCU/TCE-SP"
]

# -------------------------------------------------
# PROMPTS EXTERNALIZADOS
# -------------------------------------------------
def load_prompt(agent: str) -> str:
    """Carrega prompt externo (JSON) com base no nome do agente"""
    base_path = "./prompts"
    path = os.path.join(base_path, f"{agent}.json")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            return data.get("prompt", "")
    return f"Voc√™ √© o Agente {agent}."

# Ordem oficial dos agentes (fase preparat√≥ria completa)
AGENT_ORDER = [
    "PCA",
    "DFD",
    "ETP",
    "PESQUISA_PRECOS",
    "ITF",
    "MAPA_RISCOS",
    "TR",
    "PARECER_JURIDICO",
    "EDITAL",
    "CONTRATO",
    "FISCALIZACAO",
    "CHECKLIST"
]

# -------------------------------------------------
# FUN√á√ïES AUXILIARES
# -------------------------------------------------
def progresso(stage: str) -> str:
    marcadores = []
    for s in AGENT_ORDER:
        if st.session_state.artefatos.get(s):
            marcadores.append(f"[X] {s}")
        else:
            marcadores.append(f"[ ] {s}")
    return "üìä Progresso atual: " + " ".join(marcadores)

def proximo_artefato(stage: str) -> str:
    try:
        idx = AGENT_ORDER.index(stage)
        return AGENT_ORDER[idx + 1] if idx + 1 < len(AGENT_ORDER) else None
    except ValueError:
        return None

def call_agent(stage: str, user_text: str, history: List[Dict]) -> Dict:
    """Chama agente especializado. Retorna estrutura com insumos classificados (‚úÖ/‚ö†Ô∏è/‚ùå)."""
    system_prompt = load_prompt(stage) + "\n\nInstru√ß√µes gerais:\n"
    system_prompt += (
        "1) Seja claro e institucional.\n"
        "2) Pergunte insumos obrigat√≥rios se faltarem.\n"
        "3) Estruture sa√≠da em se√ß√µes numeradas.\n"
        "4) Classifique cada insumo em ‚úÖ Pronto, ‚ö†Ô∏è Parcial ou ‚ùå Pendente.\n"
        "5) Fundamente nas normas aplic√°veis.\n"
        f"Normas de refer√™ncia: {', '.join(NORMAS_BASE)}.\n"
        "6) Ao final, sugira o pr√≥ximo passo."
    )

    ctx = [f"{m['role']}: {m['content']}" for m in history[-4:]]
    context_block = "\n".join(ctx) if ctx else "Sem hist√≥rico relevante."

    user_prompt = (
        f"Etapa: {stage}\n"
        f"Contexto recente:\n{context_block}\n\n"
        f"Entrada do usu√°rio:\n{user_text}\n\n"
        "Responda em formato JSON estruturado:\n"
        "{ 'insumos': { 'objeto': '‚úÖ', 'justificativa': '‚ö†Ô∏è', ... }, 'resumo': 'texto estruturado' }"
    )

    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=1200
        )
        conteudo = resp.choices[0].message.content.strip()
        return json.loads(conteudo)
    except Exception as e:
        return {"erro": str(e)}

# -------------------------------------------------
# ESTADO DO CHAT
# -------------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_stage" not in st.session_state:
    st.session_state.current_stage = "PCA"
if "artefatos" not in st.session_state:
    st.session_state.artefatos = {}
if "log_normativo" not in st.session_state:
    st.session_state.log_normativo = []

# Mensagem inicial
if not st.session_state.messages:
    st.session_state.messages.append({
        "role": "assistant",
        "content": (
            "Ol√°! Sou o **Agente Orquestrador** do Synapse.IA. "
            "Antes de iniciar, precisamos verificar se a contrata√ß√£o est√° no **Plano de Contrata√ß√µes Anual (PCA)**. "
            "Deseja come√ßar pelo PCA?"
        )
    })

# Render hist√≥rico
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# Entrada do usu√°rio
user_input = st.chat_input("Descreva seu pedido ou responda √†s perguntas do agente...")

if user_input:
    # salvar entrada
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # chamar agente
    stage = st.session_state.current_stage
    resposta = call_agent(stage, user_input, st.session_state.messages)

    # salvar e mostrar resultado
    if "resumo" in resposta:
        st.session_state.artefatos[stage] = resposta
        st.session_state.messages.append({"role": "assistant", "content": resposta["resumo"]})
        with st.chat_message("assistant"):
            st.markdown(resposta["resumo"])

        # log normativo
        st.session_state.log_normativo.append({
            "etapa": stage,
            "entrada": user_input,
            "saida": resposta
        })

        # sugerir pr√≥xima etapa
        prox = proximo_artefato(stage)
        if prox:
            st.session_state.current_stage = prox
            sugestao = f"{progresso(stage)}\n\nüëâ Pr√≥ximo passo sugerido: **{prox}**. Deseja avan√ßar?"
            st.session_state.messages.append({"role": "assistant", "content": sugestao})
            with st.chat_message("assistant"):
                st.markdown(sugestao)
